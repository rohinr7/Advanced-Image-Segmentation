{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the root directory to sys.path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, widgets, VBox, HBox\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import random\n",
    "from src.dataset import ProjectDatasets\n",
    "from src.models.UNet import UNet\n",
    "from src.utils.helpers import visualize_batch_with_colorbar\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/cache-sasifchaudhr/ipykernel_2472603/710902063.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoints_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints_path = \"/net/travail/rramesh/AdvanceimageProcessing/Semantic-Segmentation-for-Autonomous-Driving/experiments/checkpoint_epoch_10.pth\"\n",
    "checkpoints_path = \"/net/cremi/sasifchaudhr/espaces/travail/Semantic-Segmentation-for-Autonomous-Driving/experiments/experiment_20241220-131602/checkpoints/checkpoint_epoch_10.pth\"\n",
    "\n",
    "transform = Compose([ToTensor(), Normalize(mean=[0.5], std=[0.5])])\n",
    "dataset = ProjectDatasets(root_path=\"/net/ens/am4ip/datasets/project-dataset\", transform=transform)\n",
    "sample = dataset[0]  # Should return 4 values\n",
    "print(len(sample))  # Should print 4\n",
    "\n",
    "model = UNet(in_channels=3, out_channels=30)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Pre-warm CUDA\n",
    "if torch.cuda.is_available():\n",
    "    _ = torch.randn(1).to(device)\n",
    "\n",
    "checkpoint = torch.load(checkpoints_path, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "_, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (inputs, targets, _) in enumerate(val_loader):\n",
    "#     with torch.no_grad():\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "#         predictions = model(inputs)\n",
    "#         predictions = torch.argmax(predictions, dim=1)  # Assuming output is logits\n",
    "        \n",
    "#         print(f\"The shape of the prediction is {predictions.shape}\")  \n",
    "#        # Check intensity range of predictions\n",
    "#         max_intensity = torch.max(predictions).item()\n",
    "#         min_intensity = torch.min(predictions).item()\n",
    "#         print(f\"The maximum intensity of the prediction is {max_intensity} and the minimum is {min_intensity}\")\n",
    "        \n",
    "#     visualize_batch_with_colorbar(inputs, predictions, targets, batch_idx, num_samples=3)\n",
    "#     break# Visualize only the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping RGB pixel in prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the color_to_class mapping to get class_to_color mapping\n",
    "color_to_class = {\n",
    "    (0, 0, 0): 0,            # Unlabeled\n",
    "    (111, 74, 0): 1,         # Dynamic\n",
    "    (81, 0, 81): 2,          # Ground\n",
    "    (128, 64, 128): 3,       # Road\n",
    "    (244, 35, 232): 4,       # Sidewalk\n",
    "    (250, 170, 160): 5,      # Parking\n",
    "    (230, 150, 140): 6,      # Rail track\n",
    "    (70, 70, 70): 7,         # Building\n",
    "    (102, 102, 156): 8,      # Wall\n",
    "    (190, 153, 153): 9,      # Fence\n",
    "    (180, 165, 180): 10,     # Guard rail\n",
    "    (150, 100, 100): 11,     # Bridge\n",
    "    (150, 120, 90): 12,      # Tunnel\n",
    "    (153, 153, 153): 13,     # Pole\n",
    "    (250, 170, 30): 14,      # Traffic light\n",
    "    (220, 220, 0): 15,       # Traffic sign\n",
    "    (107, 142, 35): 16,      # Vegetation\n",
    "    (152, 251, 152): 17,     # Terrain\n",
    "    (70, 130, 180): 18,      # Sky\n",
    "    (220, 20, 60): 19,       # Person\n",
    "    (255, 0, 0): 20,         # Rider\n",
    "    (0, 0, 142): 21,         # Car\n",
    "    (0, 0, 70): 22,          # Truck\n",
    "    (0, 60, 100): 23,        # Bus\n",
    "    (0, 0, 90): 24,          # Caravan\n",
    "    (0, 0, 110): 25,         # Trailer\n",
    "    (0, 80, 100): 26,        # Train\n",
    "    (0, 0, 230): 27,         # Motorcycle\n",
    "    (119, 11, 32): 29        # Bicycle\n",
    "}\n",
    "\n",
    "class_to_color = {v: k for k, v in color_to_class.items()}\n",
    "\n",
    "def map_classes_to_colors(predictions, class_to_color):\n",
    "    \"\"\"\n",
    "    Map class IDs to RGB colors for a segmentation map.\n",
    "\n",
    "    Args:\n",
    "        predictions (torch.Tensor): Tensor of shape (H, W) containing class IDs.\n",
    "        class_to_color (dict): Mapping from class IDs to RGB colors.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: RGB image of shape (H, W, 3).\n",
    "    \"\"\"\n",
    "    height, width = predictions.shape\n",
    "    rgb_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    for class_id, color in class_to_color.items():\n",
    "        rgb_image[predictions == class_id] = color  # Map each class to its color\n",
    "    \n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example: Visualizing predictions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (inputs, targets, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_loader):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      4\u001b[0m         inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# Example: Visualizing predictions\n",
    "for batch_idx, (inputs, targets, _) in enumerate(val_loader):\n",
    "    with torch.no_grad():\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        predictions = model(inputs)\n",
    "        predictions = torch.argmax(predictions, dim=1)  # Shape: [N, H, W]\n",
    "\n",
    "        print(f\"the shape of the targets is {targets.shape}\")\n",
    "        print(f\"the shape of the inputs is {inputs.shape}\")\n",
    "        \n",
    "        # Convert all predictions in the batch to RGB format\n",
    "        rgb_predictions = np.stack([\n",
    "            map_classes_to_colors(predictions[i].cpu().numpy(), class_to_color) for i in range(predictions.shape[0])\n",
    "        ])  # Shape: [N, H, W, 3]\n",
    "        \n",
    "\n",
    "        rgb_targets = np.stack([\n",
    "            map_classes_to_colors(targets[i].cpu().numpy(), class_to_color) for i in range(targets.shape[0])\n",
    "        ])\n",
    "\n",
    "\n",
    "    # Visualize the batch with RGB predictions\n",
    "    visualize_batch_with_colorbar(inputs, rgb_predictions, rgb_targets, batch_idx, num_samples=8, rgb_pred=True)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VideoPlayer:\n",
    "    def __init__(self, inputs, predictions, targets, sources, image_names, rgb_pred=False, interval=0.5):\n",
    "        # Same initialization as before\n",
    "        self.inputs = inputs.cpu().numpy()\n",
    "        self.predictions = predictions\n",
    "        self.targets = targets if isinstance(targets, np.ndarray) else targets.cpu().numpy()\n",
    "        self.sources = sources\n",
    "        self.image_names = image_names\n",
    "        self.rgb_pred = rgb_pred\n",
    "        self.num_samples = inputs.shape[0]\n",
    "        self.interval = interval  # Playback speed in seconds\n",
    "\n",
    "        # State variables\n",
    "        self.current_index = 0\n",
    "        self.playing = False\n",
    "\n",
    "        # Widgets\n",
    "        self.slider = widgets.IntSlider(value=0, min=0, max=self.num_samples - 1, step=1, description=\"Frame:\")\n",
    "        self.play_button = widgets.ToggleButton(value=False, description=\"Play\", button_style=\"success\")\n",
    "        self.next_button = widgets.Button(description=\"Next\")\n",
    "        self.prev_button = widgets.Button(description=\"Previous\")\n",
    "        self.output = widgets.Output()\n",
    "\n",
    "        # Event bindings\n",
    "        self.play_button.observe(self.toggle_play, names=\"value\")\n",
    "        self.slider.observe(self.update_frame, names=\"value\")\n",
    "        self.next_button.on_click(self.next_frame)\n",
    "        self.prev_button.on_click(self.previous_frame)\n",
    "\n",
    "        # Layout\n",
    "        self.controls = widgets.HBox([self.prev_button, self.play_button, self.next_button, self.slider])\n",
    "        display(self.controls, self.output)\n",
    "\n",
    "    def display_frame(self, index):\n",
    "        \"\"\"\n",
    "        Display the frame corresponding to the given index.\n",
    "        \"\"\"\n",
    "        with self.output:\n",
    "            # Ensure the output area is cleared before redrawing\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            # Create a new figure for each frame\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "            # Normalize inputs, predictions, and targets\n",
    "            normalized_input = (self.inputs[index].transpose(1, 2, 0) + 1) / 2  # Scale inputs to [0, 1]\n",
    "            normalized_predictions = (\n",
    "                self.predictions[index] / 255.0 if self.predictions[index].max() > 1 else self.predictions[index]\n",
    "            )\n",
    "            normalized_targets = (\n",
    "                self.targets[index] / 255.0 if self.targets[index].max() > 1 else self.targets[index]\n",
    "            )\n",
    "\n",
    "            # Input image\n",
    "            ax1 = axes[0]\n",
    "            ax1.imshow(normalized_input, vmin=0, vmax=1)\n",
    "            ax1.set_title(f\"Input Image (Frame {index})\", fontsize=12)\n",
    "            ax1.axis(\"off\")\n",
    "\n",
    "            # Prediction\n",
    "            ax2 = axes[1]\n",
    "            ax2.imshow(normalized_predictions, vmin=0, vmax=1)\n",
    "            ax2.set_title(f\"Prediction (Frame {index})\", fontsize=12)\n",
    "            ax2.axis(\"off\")\n",
    "\n",
    "            # Ground truth\n",
    "            ax3 = axes[2]\n",
    "            ax3.imshow(normalized_targets, vmin=0, vmax=1)\n",
    "            ax3.set_title(f\"Ground Truth (Frame {index})\", fontsize=12)\n",
    "            ax3.axis(\"off\")\n",
    "\n",
    "            # Add source and image name\n",
    "            fig.suptitle(\n",
    "                f\"Source: {self.sources[index]} | Image Name: {self.image_names[index]}\",\n",
    "                fontsize=14,\n",
    "                y=0.98,\n",
    "            )\n",
    "\n",
    "            # Display the figure\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def toggle_play(self, change):\n",
    "        \"\"\"\n",
    "        Toggle play/pause functionality.\n",
    "        \"\"\"\n",
    "        self.playing = change[\"new\"]\n",
    "        if self.playing:\n",
    "            self.play_button.description = \"Pause\"\n",
    "            self.play_button.button_style = \"danger\"\n",
    "            self.start_playback()\n",
    "        else:\n",
    "            self.play_button.description = \"Play\"\n",
    "            self.play_button.button_style = \"success\"\n",
    "\n",
    "    def start_playback(self):\n",
    "        \"\"\"\n",
    "        Start playback in a loop until stopped or frames exhausted.\n",
    "        \"\"\"\n",
    "        while self.playing and self.current_index < self.num_samples:\n",
    "            self.display_frame(self.current_index)\n",
    "            self.slider.value = self.current_index\n",
    "            time.sleep(self.interval)  # Pause for the specified interval\n",
    "            self.current_index += 1\n",
    "            if self.current_index >= self.num_samples:\n",
    "                self.playing = False\n",
    "                self.play_button.value = False\n",
    "                self.play_button.description = \"Play\"\n",
    "                self.play_button.button_style = \"success\"\n",
    "\n",
    "    def update_frame(self, change):\n",
    "        \"\"\"\n",
    "        Update the displayed frame when the slider is adjusted.\n",
    "        \"\"\"\n",
    "        self.current_index = change[\"new\"]\n",
    "        self.display_frame(self.current_index)\n",
    "\n",
    "    def next_frame(self, _):\n",
    "        \"\"\"\n",
    "        Display the next frame.\n",
    "        \"\"\"\n",
    "        if self.current_index < self.num_samples - 1:\n",
    "            self.current_index += 1\n",
    "            self.slider.value = self.current_index\n",
    "            self.display_frame(self.current_index)\n",
    "\n",
    "    def previous_frame(self, _):\n",
    "        \"\"\"\n",
    "        Display the previous frame.\n",
    "        \"\"\"\n",
    "        if self.current_index > 0:\n",
    "            self.current_index -= 1\n",
    "            self.slider.value = self.current_index\n",
    "            self.display_frame(self.current_index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Welll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9897cd00a1b24a1b90b7b4429dfef184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Previous', style=ButtonStyle()), ToggleButton(value=False, button_style='su…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3657bbe26f574169909894e2c96213c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "class VideoPlayer:\n",
    "    def __init__(self, inputs, predictions, targets, sources, image_names, rgb_pred=False, interval=0.0):\n",
    "        \"\"\"\n",
    "        Initialize the VideoPlayer for interactive visualization.\n",
    "        \"\"\"\n",
    "        self.inputs = inputs.cpu().numpy()\n",
    "        self.predictions = predictions\n",
    "        self.targets = targets if isinstance(targets, np.ndarray) else targets.cpu().numpy()\n",
    "        self.sources = sources\n",
    "        self.image_names = image_names\n",
    "        self.rgb_pred = rgb_pred\n",
    "        self.num_samples = inputs.shape[0]\n",
    "        self.interval = interval  # Playback speed in seconds\n",
    "\n",
    "        # Normalize inputs, predictions, and targets once\n",
    "        self.normalized_inputs = (self.inputs.transpose(0, 2, 3, 1) + 1) / 2  # CHW to HWC and scale to [0, 1]\n",
    "        self.normalized_predictions = (\n",
    "            self.predictions / 255.0 if self.predictions.max() > 1 else self.predictions\n",
    "        )\n",
    "        self.normalized_targets = (\n",
    "            self.targets / 255.0 if self.targets.max() > 1 else self.targets\n",
    "        )\n",
    "\n",
    "        # State variables\n",
    "        self.current_index = 0\n",
    "        self.playing = False\n",
    "\n",
    "        # Widgets\n",
    "        self.slider = widgets.IntSlider(value=0, min=0, max=self.num_samples - 1, step=1, description=\"Frame:\")\n",
    "        self.play_button = widgets.ToggleButton(value=False, description=\"Play\", button_style=\"success\")\n",
    "        self.next_button = widgets.Button(description=\"Next\")\n",
    "        self.prev_button = widgets.Button(description=\"Previous\")\n",
    "        self.output = widgets.Output()\n",
    "\n",
    "        # Event bindings\n",
    "        self.play_button.observe(self.toggle_play, names=\"value\")\n",
    "        self.slider.observe(self.update_frame, names=\"value\")\n",
    "        self.next_button.on_click(self.next_frame)\n",
    "        self.prev_button.on_click(self.previous_frame)\n",
    "\n",
    "        # Layout\n",
    "        self.controls = widgets.HBox([self.prev_button, self.play_button, self.next_button, self.slider])\n",
    "        display(self.controls, self.output)\n",
    "\n",
    "    def display_frame(self, index):\n",
    "        \"\"\"\n",
    "        Display the frame corresponding to the given index.\n",
    "        \"\"\"\n",
    "        with self.output:\n",
    "            # Clear the output widget\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            # Create a new figure for the current frame\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "            # Input image\n",
    "            axes[0].imshow(self.normalized_inputs[index], vmin=0, vmax=1)\n",
    "            axes[0].set_title(f\"Input Image (Frame {index})\", fontsize=12)\n",
    "            axes[0].axis(\"off\")\n",
    "\n",
    "            # Prediction\n",
    "            if self.rgb_pred:\n",
    "                axes[1].imshow(self.normalized_predictions[index], vmin=0, vmax=1)\n",
    "            else:\n",
    "                axes[1].imshow(self.normalized_predictions[index], cmap=\"gray\", vmin=0, vmax=1)\n",
    "            axes[1].set_title(f\"Prediction (Frame {index})\", fontsize=12)\n",
    "            axes[1].axis(\"off\")\n",
    "\n",
    "            # Ground truth\n",
    "            axes[2].imshow(self.normalized_targets[index], vmin=0, vmax=1)\n",
    "            axes[2].set_title(f\"Ground Truth (Frame {index})\", fontsize=12)\n",
    "            axes[2].axis(\"off\")\n",
    "\n",
    "            # Add source and image name\n",
    "            fig.suptitle(\n",
    "                f\"Source: {self.sources[index]} | Image Name: {self.image_names[index]}\",\n",
    "                fontsize=14,\n",
    "                y=0.98,\n",
    "            )\n",
    "\n",
    "            # Adjust layout and show\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def toggle_play(self, change):\n",
    "        \"\"\"\n",
    "        Toggle play/pause functionality.\n",
    "        \"\"\"\n",
    "        self.playing = change[\"new\"]\n",
    "        if self.playing:\n",
    "            self.play_button.description = \"Pause\"\n",
    "            self.play_button.button_style = \"danger\"\n",
    "            self.start_playback()\n",
    "        else:\n",
    "            self.play_button.description = \"Play\"\n",
    "            self.play_button.button_style = \"success\"\n",
    "\n",
    "    def start_playback(self):\n",
    "        \"\"\"\n",
    "        Start playback in a loop until stopped or frames exhausted.\n",
    "        \"\"\"\n",
    "        while self.playing and self.current_index < self.num_samples:\n",
    "            self.display_frame(self.current_index)\n",
    "            self.slider.value = self.current_index\n",
    "            time.sleep(self.interval)  # Pause for the specified interval\n",
    "            self.current_index += 1\n",
    "            if self.current_index >= self.num_samples:\n",
    "                self.playing = False\n",
    "                self.play_button.value = False\n",
    "                self.play_button.description = \"Play\"\n",
    "                self.play_button.button_style = \"success\"\n",
    "\n",
    "    def update_frame(self, change):\n",
    "        \"\"\"\n",
    "        Update the displayed frame when the slider is adjusted.\n",
    "        \"\"\"\n",
    "        self.current_index = change[\"new\"]\n",
    "        self.display_frame(self.current_index)\n",
    "\n",
    "    def next_frame(self, _):\n",
    "        \"\"\"\n",
    "        Display the next frame.\n",
    "        \"\"\"\n",
    "        if self.current_index < self.num_samples - 1:\n",
    "            self.current_index += 1\n",
    "            self.slider.value = self.current_index\n",
    "            self.display_frame(self.current_index)\n",
    "\n",
    "    def previous_frame(self, _):\n",
    "        \"\"\"\n",
    "        Display the previous frame.\n",
    "        \"\"\"\n",
    "        if self.current_index > 0:\n",
    "            self.current_index -= 1\n",
    "            self.slider.value = self.current_index\n",
    "            self.display_frame(self.current_index)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "# Assuming inputs, predictions, and targets are already computed and available\n",
    "# Replace `map_classes_to_colors` and other functions with your own utilities\n",
    "\n",
    "for batch_idx, (inputs, targets, sources, image_names) in enumerate(val_loader):\n",
    "    with torch.no_grad():\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        predictions = model(inputs)\n",
    "        predictions = torch.argmax(predictions, dim=1)  # Shape: [N, H, W]\n",
    "\n",
    "        # Convert predictions and targets to RGB\n",
    "        rgb_predictions = np.stack([\n",
    "            map_classes_to_colors(predictions[i].cpu().numpy(), class_to_color) for i in range(predictions.shape[0])\n",
    "        ])  # Shape: [N, H, W, 3]\n",
    "\n",
    "        rgb_targets = np.stack([\n",
    "            map_classes_to_colors(targets[i].cpu().numpy(), class_to_color) for i in range(targets.shape[0])\n",
    "        ])\n",
    "\n",
    "    # Initialize VideoPlayer with sources and image names\n",
    "    VideoPlayer(inputs, rgb_predictions, rgb_targets, sources, image_names, rgb_pred=True)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is starting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35b9363ebf34f74bf0e75799fc76f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Previous', style=ButtonStyle()), ToggleButton(value=False, button_style='su…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f24a1beb384ef7955e18a5cbc79467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "\n",
    "class VideoPlayer:\n",
    "    def __init__(self, inputs, predictions, targets, sources, image_names, rgb_pred=False, interval=0.0):\n",
    "        \"\"\"\n",
    "        Initialize the VideoPlayer for interactive visualization.\n",
    "        \"\"\"\n",
    "        # Precompute normalized data\n",
    "        self.normalized_inputs = (inputs.cpu().numpy().transpose(0, 2, 3, 1) + 1) / 2  # CHW -> HWC, scale to [0, 1]\n",
    "        self.normalized_predictions = (\n",
    "            predictions / 255.0 if predictions.max() > 1 else predictions\n",
    "        )\n",
    "        self.normalized_targets = (\n",
    "            targets / 255.0 if targets.max() > 1 else targets\n",
    "        )\n",
    "\n",
    "        # Store metadata\n",
    "        self.sources = sources\n",
    "        self.image_names = image_names\n",
    "        self.rgb_pred = rgb_pred\n",
    "        self.num_samples = inputs.shape[0]\n",
    "        self.interval = interval  # Playback speed in seconds\n",
    "\n",
    "        # State variables\n",
    "        self.current_index = 0\n",
    "        self.playing = False\n",
    "\n",
    "        # Widgets\n",
    "        self.slider = widgets.IntSlider(value=0, min=0, max=self.num_samples - 1, step=1, description=\"Frame:\")\n",
    "        self.play_button = widgets.ToggleButton(value=False, description=\"Play\", button_style=\"success\")\n",
    "        self.next_button = widgets.Button(description=\"Next\")\n",
    "        self.prev_button = widgets.Button(description=\"Previous\")\n",
    "        self.output = widgets.Output()\n",
    "\n",
    "        # Event bindings\n",
    "        self.play_button.observe(self.toggle_play, names=\"value\")\n",
    "        self.slider.observe(self.update_frame, names=\"value\")\n",
    "        self.next_button.on_click(self.next_frame)\n",
    "        self.prev_button.on_click(self.previous_frame)\n",
    "\n",
    "        self.normalized_inputs = np.clip((inputs.cpu().numpy().transpose(0, 2, 3, 1) + 1) / 2, 0, 1)\n",
    "        self.normalized_predictions = np.clip(predictions / 255.0, 0, 1)  # Normalize to [0, 1]\n",
    "        self.normalized_targets = np.clip(targets / 255.0, 0, 1)          # Normalize to [0, 1]\n",
    "\n",
    "        # Layout\n",
    "        self.controls = widgets.HBox([self.prev_button, self.play_button, self.next_button, self.slider])\n",
    "        display(self.controls, self.output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def display_frame(self, index):\n",
    "        \"\"\"\n",
    "        Efficiently update the frame using persistent AxesImage objects.\n",
    "        \"\"\"\n",
    "        with self.output:\n",
    "            # Clear output widget\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            if not hasattr(self, \"fig\") or self.fig is None:\n",
    "                print(\"Creating figure for the first time\")\n",
    "                # Create figure and axes only once\n",
    "                self.fig, self.axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                \n",
    "                # Initialize AxesImage objects for updating\n",
    "                self.input_im = self.axes[0].imshow(self.normalized_inputs[index], vmin=0, vmax=1)\n",
    "                self.pred_im = self.axes[1].imshow(self.normalized_predictions[index], vmin=0, vmax=1)\n",
    "                self.gt_im = self.axes[2].imshow(self.normalized_targets[index], vmin=0, vmax=1)\n",
    "\n",
    "                # Set titles and axes properties\n",
    "                self.axes[0].set_title(\"Input Image\", fontsize=12)\n",
    "                self.axes[0].axis(\"off\")\n",
    "                self.axes[1].set_title(\"Prediction\", fontsize=12)\n",
    "                self.axes[1].axis(\"off\")\n",
    "                self.axes[2].set_title(\"Ground Truth\", fontsize=12)\n",
    "                self.axes[2].axis(\"off\")\n",
    "\n",
    "                # Add metadata\n",
    "                self.fig.suptitle(\n",
    "                    f\"Source: {self.sources[index]} | Image Name: {self.image_names[index]}\",\n",
    "                    fontsize=14,\n",
    "                    y=0.98,\n",
    "                )\n",
    "\n",
    "                # Adjust layout\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"Updating frame {index}\")\n",
    "                # Update existing AxesImage objects\n",
    "                self.input_im.set_array(self.normalized_inputs[index])\n",
    "                self.pred_im.set_array(self.normalized_predictions[index])\n",
    "                self.gt_im.set_array(self.normalized_targets[index])\n",
    "\n",
    "                # Update metadata and redraw\n",
    "                self.fig.suptitle(\n",
    "                    f\"Source: {self.sources[index]} | Image Name: {self.image_names[index]}\",\n",
    "                    fontsize=14,\n",
    "                    y=0.98,\n",
    "                )\n",
    "                self.fig.canvas.draw()\n",
    "                self.fig.canvas.flush_events()  # Ensure immediate update\n",
    "\n",
    "    def toggle_play(self, change):\n",
    "        \"\"\"\n",
    "        Toggle play/pause functionality.\n",
    "        \"\"\"\n",
    "        self.playing = change[\"new\"]\n",
    "        if self.playing:\n",
    "            self.play_button.description = \"Pause\"\n",
    "            self.play_button.button_style = \"danger\"\n",
    "            self.start_playback()\n",
    "        else:\n",
    "            self.play_button.description = \"Play\"\n",
    "            self.play_button.button_style = \"success\"\n",
    "\n",
    "    def start_playback(self):\n",
    "        \"\"\"\n",
    "        Start playback in a loop until stopped or frames exhausted.\n",
    "        \"\"\"\n",
    "        while self.playing and self.current_index < self.num_samples:\n",
    "            self.display_frame(self.current_index)\n",
    "            self.slider.value = self.current_index\n",
    "            time.sleep(self.interval)  # Pause for the specified interval\n",
    "            self.current_index += 1\n",
    "            if self.current_index >= self.num_samples:\n",
    "                self.playing = False\n",
    "                self.play_button.value = False\n",
    "                self.play_button.description = \"Play\"\n",
    "                self.play_button.button_style = \"success\"\n",
    "\n",
    "    def update_frame(self, change):\n",
    "        \"\"\"\n",
    "        Update the displayed frame when the slider is adjusted.\n",
    "        \"\"\"\n",
    "        self.current_index = change[\"new\"]\n",
    "        self.display_frame(self.current_index)\n",
    "\n",
    "    def next_frame(self, _):\n",
    "        \"\"\"\n",
    "        Display the next frame.\n",
    "        \"\"\"\n",
    "        if self.current_index < self.num_samples - 1:\n",
    "            self.current_index += 1\n",
    "            self.slider.value = self.current_index\n",
    "            self.display_frame(self.current_index)\n",
    "\n",
    "    def previous_frame(self, _):\n",
    "        \"\"\"\n",
    "        Display the previous frame.\n",
    "        \"\"\"\n",
    "        if self.current_index > 0:\n",
    "            self.current_index -= 1\n",
    "            self.slider.value = self.current_index\n",
    "            self.display_frame(self.current_index)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "# Assuming inputs, predictions, and targets are already computed and available\n",
    "# Replace `map_classes_to_colors` and other functions with your own utilities\n",
    "\n",
    "for batch_idx, (inputs, targets, sources, image_names) in enumerate(val_loader):\n",
    "    with torch.no_grad():\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        predictions = model(inputs)\n",
    "        predictions = torch.argmax(predictions, dim=1)  # Shape: [N, H, W]\n",
    "\n",
    "        # Convert predictions and targets to RGB\n",
    "        rgb_predictions = np.stack([\n",
    "            map_classes_to_colors(predictions[i].cpu().numpy(), class_to_color) for i in range(predictions.shape[0])\n",
    "        ])  # Shape: [N, H, W, 3]\n",
    "\n",
    "        rgb_targets = np.stack([\n",
    "            map_classes_to_colors(targets[i].cpu().numpy(), class_to_color) for i in range(targets.shape[0])\n",
    "        ])\n",
    "    print(\"it is starting\")\n",
    "    VideoPlayer(inputs, rgb_predictions, rgb_targets, sources, image_names, rgb_pred=True)\n",
    "    # Initialize VideoPlayer with sources and image names\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
